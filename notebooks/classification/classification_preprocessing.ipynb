{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "effd4b57",
   "metadata": {},
   "source": [
    "# Classification Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef306a43",
   "metadata": {},
   "source": [
    "## ‚¨áÔ∏è Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e3ce08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, precision_recall_fscore_support\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import spacy\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890198ee",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Preprocessing\n",
    "### Downloading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d730c23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data  = pd.read_csv('../../data/RAW_recipes.csv')\n",
    "data.set_index('id', inplace=True)\n",
    "columns = [\"tags\", \"steps\", \"ingredients\", \"nutrition\"]\n",
    "\n",
    "for i in columns:\n",
    "    data[i] = data[i].apply(ast.literal_eval)\n",
    "\n",
    "data.drop(columns=[\"contributor_id\", \"submitted\"], inplace=True, errors=\"ignore\")\n",
    "data.dropna(subset=[\"name\"], inplace=True)\n",
    "data = data[data['minutes'] < 300]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790ac1f9-ffdd-4d17-b904-891607353328",
   "metadata": {},
   "source": [
    "### Stop Words Removal & Tokenization on recipe Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c11f5b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/maxboc/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/maxboc/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Initialize the lemmatizer and stopwords list\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "additional = {\n",
    "    \"minutes\", \"easiest\", \"ever\", \"aww\", \"i\", \"can\", \"t\", \"believe\", \"it\", \"s\", \"stole\", \"the\", \"idea\", \"from\",\"mirj\", \"andrea\", \" s \", \"andreas\",\n",
    "    \"viestad\", \"andes\", \"andersen\", \"an\", \"ana\", \"amy\", \"2 ww points\", \"on demand\", \"anelia\", \"amazing\",\n",
    "    \"ashley\", \"ashton\", \"amazing\", \"make\", \"house\", \"smell\", \"malcolm\", \"amazingly\", \"killer\", \"perfect\",\n",
    "    \"addictive\", \"leave\", \"u\", \"licking\", \"ur\", \"finger\", \"clean\", \"th\", \"recipe\", \"special\", \"time\", \"favorite\",\n",
    "    \"aunt\", \"jane\", \"soft\", \"and\", \"moist\", \"licking\", \"famous\", \"non fruitcake\", \"true\", \"later\",\n",
    "    \"nonbeliever\", \"believer\", \"comfort\", \"ultimate\", \"lover\", \"love\", \"easy\", \"ugly\", \"cc\", \"uncle\", \"bill\", \"tyler\",\n",
    "    \"unbelievably\", \"unbelievable\", \"healthy\", \"fat\", \"free\", \"un\", \"melt\", \"mouth\", \"ummmmm\", \"umm\", \"ummmy\", \"nummy\", \"ummmm\", \"unattended\",\n",
    "    \"unbaked\", \"ultra\", \"ultimately\", \"yummy\", \"rich\", \"quick\", \"rachael\", \"ray\", \"fail\", \"party\", \"florence\",\n",
    "    \"fast\", \"light\", \"low\", \"carb\", \"snack\", \"wedding\", \"anniversary\", \"anne\", \"marie\", \"annemarie\", \"annette\", \"funicello\", \"syms\",\n",
    "    \"byrn\", \"mike\", \"willan\", \"summer\", \"autumn\", \"winter\", \"spring\", \"burrel\", \"anna\", \"tres\", \"sweet\", \"uber\",\n",
    "    \"homemade\", \"ann\",\"best\",\"j\", \"anite\", \"anitas\", \"anman\", \"angie\", \"angry\", \"simple\", \"difficult\", \"andy\", \"andrew\", \"ancient\", \"still\", \"another\", \"best\", \"go\",\n",
    "    \"grant\", \"grandma\", \"amusement\", \"park\", \"instruction\", \"kitchen\", \"test\", \"ww\", \"almost\", \"empty\", \"dressing\", \"instant\", \"like\", \"le\", \"virtually\",\n",
    "    \"home\", \"made\", \"guilt\", \"guilty\", \"delicious\", \"parfait\", \"forgotten\", \"forget\", \"forevermama\", \"diet\", \"can\", \"real\", \"former\",\n",
    "    \"miss\", \"fabulous\", \"forever\", \"authentic\", \"fortnum\", \"mason\", \"kid\", \"foolproof\", \"football\", \"season\", \"diabetic\",\n",
    "    \"two\", \"small\", \"one\", \"three\", \"four\", \"five\", \"thanksgiving\", \"dream\", \"foothill\", \"paula\", \"deen\", \"food\", \"processor\", \"safari\", \"processor\",\n",
    "    \"traditional\", \"forbidden\", \"flavorful\", \"grandmag\", \"grandmama\", \"grandmaman\", \"grandma\", \"grandmom\", \"lena\", \"alicia\", \"alisa\", \"alice\", \"ali\", \"bit\", \"different\",\n",
    "    \"eat\", \"family\", \"global\", \"gourmet\", \"yam\", \"yam\", \"emotional\", \"balance\", \"tonight\", \"feel\", \"cooking\", \"got\", \"birthday\", \"air\", \"way\", \"mr\", \"never\", \"weep\", \"half\",\n",
    "    \"anything\", \"pour\", \"put\", \"fork\", \"say\", \"stove\", \"top\", \"thought\", \"prize\", \"winning\", \"add\", \"ad\", \"good\", \"better\", \"da\", \"style\", \"even\", \"bran\", \"fake\", \"fire\", \"beautiful\"\n",
    "    \"l\", \"game\", \"day\", \"hate\", \"world\", \"minute\", \"type\", \"starbucks\", \"biggest\", \"dressed\", \"summertime\", \"elmer\", \"johnny\", \"depp\", \"c\", \"p\", \"h\", \"clove\", \"er\", \"star\", \"week\",\n",
    "    \"affair\", \"elegant\", \"student\", \"z\", \"whole\", \"lotta\", \"w\", \"z\", \"b\", \"aaron\", \"craze\", \"a\", \"abc\", \"absolute\", \"absolut\", \"absolutely\", \"perfection\", \"delightful\", \"lazy\", \"morning\",\n",
    "    \"abuelo\", \"abuelito\", \"abuelita\", \"abuela\", \"acadia\", \"accidental\", \"adam\", \"little\", \"interest\", \"addicting\", \"addie\", \"adele\", \"adelaide\", \"adi\", \"adie\", \"adriana\",\n",
    "    \"adult\", \"affordable\", \"alison\", \"holst\", \"purpose\", \"allegheny\", \"allegedly\", \"original\", \"allergic\", \"ex\", \"allergy\", \"allergen\", \"allen\", \"poorman\", \"backyard\",\n",
    "    \"alton\", \"brown\", \"whatever\", \"anthony\", \"anytime\", \"april\", \"fool\", \"ya\", \"fooled\", \"sandra\", \"lee\", \"edna\", \"emma\", \"emy\", \"evy\", \"eva\", 'evelyn', \"fannie\", \"fanny\", \"flo\", \"gladys\", \"helen\", \"grace\", \"ira\", \"irma\",\n",
    "    \"isse\", \"jean\", \"janet\", \"jenny\", \"juju\", \"judy\", \"kathy\", \"kathi\", \"kellie\", \"kelly\", \"laura\", \"lee\", \"kay\", \"kathleen\", \"laura\", \"lee\", \"lesley\", \"lil\", \"linda\", \"liz\", \"lois\", \"louisse\",\n",
    "    \"mag\", 'martguerite', \"margie\", \"marge\", \"maggie\", \"martha\", \"marylin\", \"marion\", \"mary\", \"marthy\", \"melody\", \"michel\", \"meda\", \"millie\", \"muriel\", \"myrna\", \"nelda\", \"nancy\", \"paulie\", \"phillis\", \"rae\", \"rebecca\",\n",
    "    \"rose\", \"sadie\", \"sarah\", \"sara\", \"sue\", \"susan\", \"teresa\", \"theresa\", \"auntie\", \"em\", \"barbara\", \"barb\", \"irene\", \"lolo\", \"lori\", \"lu\", \"maebelle\",\n",
    "    \"aunty\", \"aussie\", \"aurora\", \"austin\", \"l\", \"q\"\n",
    "    \n",
    "    }\n",
    "stop_words.update(additional) \n",
    "\n",
    "# Function to clean recipe names\n",
    "def clean_recipe_names(recipes):\n",
    "    cleaned_recipes = []\n",
    "    \n",
    "    for recipe in recipes:\n",
    "\n",
    "        recipe = recipe.lower()\n",
    "        recipe = re.sub(r'[^a-z\\s]', '', recipe)\n",
    "        \n",
    "        recipe_words = recipe.split()\n",
    "        \n",
    "        # Lemmatize first\n",
    "        recipe_words = [lemmatizer.lemmatize(word) for word in recipe_words]\n",
    "        \n",
    "        recipe_words = [word for word in recipe_words if word not in stop_words]\n",
    "        \n",
    "        cleaned_recipe = \" \".join(recipe_words)\n",
    "        cleaned_recipes.append(cleaned_recipe)\n",
    "    \n",
    "    return cleaned_recipes\n",
    "\n",
    "\n",
    "data['name'] = clean_recipe_names(data['name'])\n",
    "\n",
    "data.dropna(subset=['name', 'description'], inplace=True)\n",
    "data.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ac3db803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    autumn is my favorite time of year to cook! th...\n",
       "1    this recipe calls for the crust to be prebaked...\n",
       "2    this modified version of 'mom's' chili was a h...\n",
       "3    this is a super easy, great tasting, make ahea...\n",
       "4    my dh's amish mother raised him on this recipe...\n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"description\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b38f321-2549-4cb6-a9f8-afa5368f5b00",
   "metadata": {},
   "source": [
    "### Cleaning Cuisine, tags, steps and ingredients features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0717fe09",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"description\"] = data[\"description\"].apply(lambda x: x.lower())\n",
    "columns = [\"tags\", \"steps\", \"ingredients\"]\n",
    "for c in columns:\n",
    "    data[c] = data[c].apply(lambda x: [s.lower() for s in x])\n",
    "\n",
    "data[\"steps_strings\"] = data[\"steps\"].apply(lambda x: ' '.join(x))\n",
    "data[\"ingredients_text\"] = data[\"ingredients\"].apply(lambda x: ' '.join(x))\n",
    "data[\"tags_text\"] = data[\"tags\"].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e34bfae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "TAG2CLASS = {\n",
    "    # North America ‚Äì United States\n",
    "    \"american\": [\"North America ‚Äì United States\"],\n",
    "    \"north-american\": [\"North America ‚Äì United States\"],\n",
    "    \"northeastern-united-states\": [\"North America ‚Äì United States\"],\n",
    "    \"californian\": [\"North America ‚Äì United States\"],\n",
    "    \"native-american\": [\"North America ‚Äì United States\"],\n",
    "    \"pennsylvania-dutch\": [\"North America ‚Äì United States\"],\n",
    "    \"hawaiian\": [\"North America ‚Äì United States\"],\n",
    "\n",
    "    # North America ‚Äì Canada\n",
    "    \"canadian\": [\"North America ‚Äì Canada\"],\n",
    "    \"british-columbian\": [\"North America ‚Äì Canada\"],\n",
    "    \"quebec\": [\"North America ‚Äì Canada\"],\n",
    "\n",
    "    # Central America & Caribbean\n",
    "    \"mexican\": [\"Mexican\", \"Central America & Caribbean\"],\n",
    "    \"costa-rican\": [\"Central America & Caribbean\"],\n",
    "    \"guatemalan\": [\"Central America & Caribbean\"],\n",
    "    \"caribbean\": [\"Central America & Caribbean\"],\n",
    "    \"cuban\": [\"Central America & Caribbean\"],\n",
    "    \"puerto-rican\": [\"Central America & Caribbean\"],\n",
    "    \"creole\": [\"Central America & Caribbean\"],\n",
    "\n",
    "    # South America\n",
    "    \"argentine\": [\"South America\"],\n",
    "    \"brazilian\": [\"South America\"],\n",
    "    \"peruvian\": [\"South America\"],\n",
    "    \"chilean\": [\"South America\"],\n",
    "    \"colombian\": [\"South America\"],\n",
    "    \"venezuelan\": [\"South America\"],\n",
    "    \"ecuadorean\": [\"South America\"],\n",
    "\n",
    "    # Europe ‚Äì Western\n",
    "    \"french\": [\"French\", \"Europe ‚Äì Western\"],\n",
    "    \"english\": [\"Europe ‚Äì Western\"],\n",
    "    \"scottish\": [\"Europe ‚Äì Western\"],\n",
    "    \"irish\": [\"Europe ‚Äì Western\"],\n",
    "    \"welsh\": [\"Europe ‚Äì Western\"],\n",
    "    \"dutch\": [\"Europe ‚Äì Western\"],\n",
    "    \"belgian\": [\"Europe ‚Äì Western\"],\n",
    "    \"austrian\": [\"Europe ‚Äì Western\"],\n",
    "    \"german\": [\"Europe ‚Äì Western\"],\n",
    "    \"italian\": [\"Italian\", \"Europe ‚Äì Western\"],\n",
    "    \"portuguese\": [\"Europe ‚Äì Western\"],\n",
    "    \"spanish\": [\"Spanish\", \"Europe ‚Äì Western\"],\n",
    "    \"greek\": [\"Greek\", \"Europe ‚Äì Western\"],\n",
    "\n",
    "    # Europe ‚Äì Northern\n",
    "    \"swedish\": [\"Europe ‚Äì Northern\"],\n",
    "    \"norwegian\": [\"Europe ‚Äì Northern\"],\n",
    "    \"finnish\": [\"Europe ‚Äì Northern\"],\n",
    "    \"icelandic\": [\"Europe ‚Äì Northern\"],\n",
    "    \"danish\": [\"Europe ‚Äì Northern\"],\n",
    "\n",
    "    # Europe ‚Äì Eastern/Central\n",
    "    \"russian\": [\"Europe ‚Äì Eastern\"],\n",
    "    \"hungarian\": [\"Europe ‚Äì Eastern\"],\n",
    "    \"czech\": [\"Europe ‚Äì Eastern\"],\n",
    "    \"georgian\": [\"Europe ‚Äì Eastern\"],\n",
    "\n",
    "    # Middle East & North Africa (MENA)\n",
    "    \"middle-eastern\": [\"Middle East & North Africa\"],\n",
    "    \"turkish\": [\"Middle East & North Africa\"],\n",
    "    \"lebanese\": [\"Middle East & North Africa\"],\n",
    "    \"iranian-persian\": [\"Middle East & North Africa\"],\n",
    "    \"iraqi\": [\"Middle East & North Africa\"],\n",
    "    \"palestinian\": [\"Middle East & North Africa\"],\n",
    "    \"saudi-arabian\": [\"Middle East & North Africa\"],\n",
    "    \"egyptian\": [\"Middle East & North Africa\"],\n",
    "    \"moroccan\": [\"Middle East & North Africa\"],\n",
    "    \"libyan\": [\"Middle East & North Africa\"],\n",
    "    \"algerian\": [\"Middle East & North Africa\"],\n",
    "    \"tunisian\": [\"Middle East & North Africa\"],\n",
    "\n",
    "    # Asia ‚Äì East\n",
    "    \"chinese\": [\"Chinese\", \"Asia ‚Äì East\"],\n",
    "    \"beijing\": [\"Chinese\", \"Asia ‚Äì East\"],\n",
    "    \"chinese-new-year\": [\"Chinese\", \"Asia ‚Äì East\"],\n",
    "    \"japanese\": [\"Japanese\", \"Asia ‚Äì East\"],\n",
    "    \"korean\": [\"Korean\", \"Asia ‚Äì East\"],\n",
    "    \"mongolian\": [\"Asia ‚Äì East\"],\n",
    "\n",
    "    # Asia ‚Äì Southeast\n",
    "    \"vietnamese\": [\"Asia ‚Äì Southeast\"],\n",
    "    \"indonesian\": [\"Asia ‚Äì Southeast\"],\n",
    "    \"malaysian\": [\"Asia ‚Äì Southeast\"],\n",
    "    \"cambodian\": [\"Asia ‚Äì Southeast\"],\n",
    "    \"laotian\": [\"Asia ‚Äì Southeast\"],\n",
    "    \"thai\": [\"Thai\", \"Asia ‚Äì Southeast\"],\n",
    "    \"polynesian\": [\"Asia ‚Äì Southeast\"],\n",
    "\n",
    "    # Asia ‚Äì South\n",
    "    \"pakistani\": [\"Asia ‚Äì South\"],\n",
    "    \"nepalese\": [\"Asia ‚Äì South\"],\n",
    "    \"indian\": [\"Indian\", \"Asia ‚Äì South\"],\n",
    "\n",
    "    # Jewish Diaspora\n",
    "    \"jewish-ashkenazi\": [\"Jewish Diaspora\", \"Middle East & North Africa\"],\n",
    "    \"jewish-sephardi\": [\"Jewish Diaspora\", \"Middle East & North Africa\"],\n",
    "\n",
    "    # Catch-all / generic\n",
    "    \"asian\": [\"Asia ‚Äì General\"],\n",
    "    \"european\": [\"Europe ‚Äì General\"],\n",
    "}\n",
    "PRIORITIZED_TAGS = [\n",
    "    # Europe ‚Äì Western\n",
    "    \"french\", \"english\", \"scottish\", \"irish\", \"welsh\",\n",
    "    \"dutch\", \"belgian\", \"austrian\", \"german\", \"italian\",\n",
    "    # North America ‚Äì United States\n",
    "    \"american\", \"north-american\", \"northeastern-united-states\",\n",
    "    \"californian\", \"native-american\", \"pennsylvania-dutch\",\n",
    "    \"hawaiian\",\n",
    "    # North America ‚Äì Canada\n",
    "    \"canadian\", \"british-columbian\", \"quebec\",\n",
    "    # Central America & Caribbean\n",
    "    \"mexican\", \"costa-rican\", \"guatemalan\",\n",
    "    \"caribbean\", \"cuban\", \"puerto-rican\", \"creole\",\n",
    "    # South America\n",
    "    \"argentine\", \"brazilian\", \"peruvian\",\n",
    "    \"chilean\", \"colombian\", \"venezuelan\", \"ecuadorean\",\n",
    "    # Europe ‚Äì Northern\n",
    "    \"swedish\", \"norwegian\", \"finnish\", \"icelandic\", \"danish\",\n",
    "    # Europe ‚Äì Eastern/Central\n",
    "    \"russian\", \"hungarian\", \"czech\", \"georgian\",\n",
    "    # Europe ‚Äì Southern\n",
    "    \"portuguese\",\n",
    "    # Middle East & North Africa (MENA)\n",
    "    \"middle-eastern\", \"turkish\", \"lebanese\",\n",
    "    \"iranian-persian\", \"iraqi\", \"palestinian\",\n",
    "    \"saudi-arabian\", \"egyptian\", \"moroccan\", \"libyan\",\n",
    "    # Sub-Saharan Africa\n",
    "    \"south-african\", \"ethiopian\", \"nigerian\",\n",
    "    \"angolan\", \"sudanese\",\n",
    "    # Asia ‚Äì East\n",
    "    \"chinese\", \"beijing\", \"chinese-new-year\",\n",
    "    \"japanese\", \"korean\", \"mongolian\",\n",
    "    # Asia ‚Äì Southeast\n",
    "    \"vietnamese\", \"indonesian\", \"malaysian\",\n",
    "    \"cambodian\", \"laotian\",\n",
    "    \"polynesian\",\n",
    "    # Asia ‚Äì South\n",
    "    \"pakistani\", \"nepalese\",\n",
    "    # Jewish Diaspora\n",
    "    \"jewish-ashkenazi\", \"jewish-sephardi\",\n",
    "    # Finally, the generic catch-alls\n",
    "    \"asian\", \"european\",\n",
    "]\n",
    "\n",
    "_tag_rank = {tag: idx for idx, tag in enumerate(PRIORITIZED_TAGS)}\n",
    "\n",
    "def map_tags_to_cuisines(tags, cleaned_name):\n",
    "    known = set()\n",
    "\n",
    "    for t in tags:\n",
    "        if t in TAG2CLASS:\n",
    "            known.add(t)\n",
    "\n",
    "    for tag in TAG2CLASS.keys():\n",
    "        if tag.lower() in cleaned_name.lower():\n",
    "            known.add(tag)\n",
    "\n",
    "    if not known:\n",
    "        return []\n",
    "    \n",
    "    all_cuisines = []\n",
    "    for tag in known:\n",
    "        all_cuisines.extend(TAG2CLASS[tag])\n",
    "\n",
    "    unique_cuisines = []\n",
    "    for cuisine in all_cuisines:\n",
    "        if cuisine not in unique_cuisines:\n",
    "            unique_cuisines.append(cuisine)\n",
    "\n",
    "    def get_cuisine_priority(cuisine):\n",
    "        cuisine_tags = []\n",
    "        for tag in known:\n",
    "            if cuisine in TAG2CLASS[tag]:\n",
    "                cuisine_tags.append(tag)\n",
    "        \n",
    "        best_rank = min(_tag_rank.get(tag, float('inf')) for tag in cuisine_tags)\n",
    "        return best_rank\n",
    "\n",
    "    sorted_cuisines = sorted(unique_cuisines, key=get_cuisine_priority)\n",
    "    \n",
    "    return sorted_cuisines\n",
    "\n",
    "\n",
    "data['cuisines'] = data.apply(lambda row: map_tags_to_cuisines(row['tags'], row['name']), axis=1)\n",
    "\n",
    "data = data[data['cuisines'].apply(len) > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228b77a8-c77c-4659-990b-70fa5c025d88",
   "metadata": {},
   "source": [
    "### Filtering rare cuisines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3fb9c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuisine_counts = data['cuisines'].value_counts()\n",
    "\n",
    "min_samples = 50\n",
    "valid_cuisines = cuisine_counts[cuisine_counts >= min_samples].index.tolist()\n",
    "data = data[data['cuisines'].isin(valid_cuisines)].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2343fc-c5d8-4079-bad8-4bff5263c71e",
   "metadata": {},
   "source": [
    "### Expand nutrition features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b644abf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id                          name  minutes  \\\n",
      "0  137739   arriba baked squash mexican       55   \n",
      "1   31490               breakfast pizza       30   \n",
      "4   44061  amish tomato ketchup canning      190   \n",
      "5   25274               marinated olive       15   \n",
      "6   67888                 barbecued rib      120   \n",
      "\n",
      "                                                tags  n_steps  \\\n",
      "0  [60-minutes-or-less, time-to-make, course, mai...       11   \n",
      "1  [30-minutes-or-less, time-to-make, course, mai...        9   \n",
      "4  [weeknight, time-to-make, course, main-ingredi...        5   \n",
      "5  [15-minutes-or-less, time-to-make, course, mai...        4   \n",
      "6  [weeknight, time-to-make, course, main-ingredi...       10   \n",
      "\n",
      "                                               steps  \\\n",
      "0  [make a choice and proceed with recipe, depend...   \n",
      "1  [preheat oven to 425 degrees f, press dough in...   \n",
      "4  [mix all ingredients& boil for 2 1 / 2 hours ,...   \n",
      "5  [toast the fennel seeds and lightly crush them...   \n",
      "6  [in a medium saucepan combine all the ingredie...   \n",
      "\n",
      "                                         description  \\\n",
      "0  autumn is my favorite time of year to cook! th...   \n",
      "1  this recipe calls for the crust to be prebaked...   \n",
      "4  my dh's amish mother raised him on this recipe...   \n",
      "5  my italian mil was thoroughly impressed by my ...   \n",
      "6  this recipe is posted by request and was origi...   \n",
      "\n",
      "                                         ingredients  n_ingredients  \\\n",
      "0  [winter squash, mexican seasoning, mixed spice...              7   \n",
      "1  [prepared pizza crust, sausage patty, eggs, mi...              6   \n",
      "4  [tomato juice, apple cider vinegar, sugar, sal...              8   \n",
      "5  [fennel seeds, green olives, ripe olives, garl...              9   \n",
      "6  [pork spareribs, soy sauce, fresh garlic, fres...             22   \n",
      "\n",
      "                                       steps_strings  \\\n",
      "0  make a choice and proceed with recipe dependin...   \n",
      "1  preheat oven to 425 degrees f press dough into...   \n",
      "4  mix all ingredients& boil for 2 1 / 2 hours , ...   \n",
      "5  toast the fennel seeds and lightly crush them ...   \n",
      "6  in a medium saucepan combine all the ingredien...   \n",
      "\n",
      "                                    ingredients_text  \\\n",
      "0  winter squash mexican seasoning mixed spice ho...   \n",
      "1  prepared pizza crust sausage patty eggs milk s...   \n",
      "4  tomato juice apple cider vinegar sugar salt pe...   \n",
      "5  fennel seeds green olives ripe olives garlic p...   \n",
      "6  pork spareribs soy sauce fresh garlic fresh gi...   \n",
      "\n",
      "                                           tags_text  \\\n",
      "0  60-minutes-or-less time-to-make course main-in...   \n",
      "1  30-minutes-or-less time-to-make course main-in...   \n",
      "4  weeknight time-to-make course main-ingredient ...   \n",
      "5  15-minutes-or-less time-to-make course main-in...   \n",
      "6  weeknight time-to-make course main-ingredient ...   \n",
      "\n",
      "                                            cuisines  calories  total_fat  \\\n",
      "0  [North America ‚Äì United States, Mexican, Centr...      51.5        0.0   \n",
      "1                    [North America ‚Äì United States]     173.4       18.0   \n",
      "4                    [North America ‚Äì United States]     352.9        1.0   \n",
      "5  [North America ‚Äì United States, North America ...     380.7       53.0   \n",
      "6                    [North America ‚Äì United States]    1109.5       83.0   \n",
      "\n",
      "   sugar  sodium  protein  saturated_fat  carbohydrates  \n",
      "0   13.0     0.0      2.0            0.0            4.0  \n",
      "1    0.0    17.0     22.0           35.0            1.0  \n",
      "4  337.0    23.0      3.0            0.0           28.0  \n",
      "5    7.0    24.0      6.0           24.0            6.0  \n",
      "6  378.0   275.0     96.0           86.0           36.0  \n"
     ]
    }
   ],
   "source": [
    "import ast  \n",
    "def expand_nutrition_column(data):\n",
    "    data['nutrition'] = data['nutrition'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "    \n",
    "    if data['nutrition'].apply(lambda x: isinstance(x, list)).all():\n",
    "        data[['calories', 'total_fat', 'sugar', 'sodium', 'protein', 'saturated_fat', 'carbohydrates']] = pd.DataFrame(data['nutrition'].to_list(), index=data.index)\n",
    "        data.drop(columns=['nutrition'], inplace=True)\n",
    "        \n",
    "    return data\n",
    "\n",
    "data = expand_nutrition_column(data)\n",
    "\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c68a4ca-066b-40af-a711-638c28dfb03b",
   "metadata": {},
   "source": [
    "### TF-IDF on steps & ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddc75664",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_vectorizer = TfidfVectorizer(max_features=500, stop_words='english')\n",
    "steps_features = steps_vectorizer.fit_transform(data[\"steps_strings\"])\n",
    "\n",
    "ingredients_vectorizer = TfidfVectorizer(max_features=500, stop_words='english')\n",
    "ingredients_features = ingredients_vectorizer.fit_transform(data[\"ingredients_text\"])\n",
    "\n",
    "numerical_features = data[['n_steps', 'n_ingredients']].values #,'token_count', 'avg_token_length']].values\n",
    "\n",
    "feature_matrices = [\n",
    "    steps_features.toarray(),\n",
    "    ingredients_features.toarray(),\n",
    "    numerical_features\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf1cab3-ac05-4a0d-8267-62d3a924bd44",
   "metadata": {},
   "source": [
    "### Combining Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "394b98f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39mhstack(feature_matrices)\n\u001b[1;32m      3\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprimary_cuisine\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuisines\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m cuisines: cuisines[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(cuisines) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m      5\u001b[0m label_encoder \u001b[38;5;241m=\u001b[39m LabelEncoder()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "X = np.hstack(feature_matrices)\n",
    "\n",
    "data['primary_cuisine'] = data['cuisines'].apply(lambda cuisines: cuisines[0] if len(cuisines) > 0 else None)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(data['primary_cuisine'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4064d6b1-aa4c-4e2e-a252-e53e98382096",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398ecf85-313e-4689-999a-69c74e8e3453",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
